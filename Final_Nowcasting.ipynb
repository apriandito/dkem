{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCASolVZuuGuJOMsSh/O20",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apriandito/dkem/blob/main/Final_Nowcasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pytrends"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxijBExbD6Qk",
        "outputId": "5b742adb-1849-4cfe-96e2-7239381e6306"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytrends\n",
            "  Downloading pytrends-4.9.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.10/dist-packages (from pytrends) (2.32.3)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.10/dist-packages (from pytrends) (2.1.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from pytrends) (4.9.4)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->pytrends) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->pytrends) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->pytrends) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->pytrends) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0->pytrends) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0->pytrends) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0->pytrends) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0->pytrends) (2024.7.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.25->pytrends) (1.16.0)\n",
            "Downloading pytrends-4.9.2-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pytrends\n",
            "Successfully installed pytrends-4.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEQOsZ_wDszl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "from pytrends.request import TrendReq\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
        "from sklearn.feature_selection import f_regression\n",
        "import numpy as np\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "# 1. Data Collection\n",
        "\n",
        "def scrape_inflasi():\n",
        "    def scrape_page(soup):\n",
        "        table = soup.find('table', {'class': 'table table-striped table-no-bordered table-lg'})\n",
        "        data = []\n",
        "        for row in table.find_all('tr')[1:]:\n",
        "            cols = row.find_all('td')\n",
        "            if cols:\n",
        "                date = cols[0].text.strip()\n",
        "                inflation = cols[1].text.strip()\n",
        "                data.append({'Tanggal': date, 'Data Inflasi': inflation})\n",
        "        return data\n",
        "\n",
        "    url = \"https://www.bi.go.id/id/statistik/indikator/data-inflasi.aspx\"\n",
        "    session = requests.Session()\n",
        "    all_data = []\n",
        "\n",
        "    for page in range(1, 27):\n",
        "        print(f\"Scraping Inflation page {page}...\")\n",
        "        if page == 1:\n",
        "            response = session.get(url)\n",
        "        else:\n",
        "            payload = {\n",
        "                \"__EVENTTARGET\": \"ctl00$ctl54$g_1f0a867d_90e9_4a92_b1c8_de34738fc4f1$ctl00$DataPagerDataInflasi$ctl02$ctl00\",\n",
        "                \"__EVENTARGUMENT\": \"\",\n",
        "                \"__LASTFOCUS\": \"\",\n",
        "                \"__VIEWSTATE\": soup.find('input', {'name': '__VIEWSTATE'})['value'],\n",
        "                \"__VIEWSTATEGENERATOR\": soup.find('input', {'name': '__VIEWSTATEGENERATOR'})['value'],\n",
        "                \"__EVENTVALIDATION\": soup.find('input', {'name': '__EVENTVALIDATION'})['value'],\n",
        "            }\n",
        "            response = session.post(url, data=payload)\n",
        "\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        page_data = scrape_page(soup)\n",
        "        all_data.extend(page_data)\n",
        "\n",
        "    return pd.DataFrame(all_data)\n",
        "\n",
        "def fetch_google_trends(keywords):\n",
        "    pytrends = TrendReq(hl='id-ID', tz=420)\n",
        "    df_trends = pd.DataFrame()\n",
        "\n",
        "    for keyword in keywords:\n",
        "        print(f\"Fetching Google Trends data for '{keyword}'...\")\n",
        "        pytrends.build_payload([keyword], cat=0, timeframe='today 5-y', geo='ID', gprop='')\n",
        "        interest_over_time_df = pytrends.interest_over_time()\n",
        "        df_trends[keyword] = interest_over_time_df[keyword]\n",
        "        time.sleep(2)\n",
        "\n",
        "    return df_trends\n",
        "\n",
        "# 2. Data Preprocessing\n",
        "\n",
        "def improved_preprocess_data(df_inflasi, df_trends, keywords):\n",
        "    bulan_dict = {\n",
        "        'Januari': 'January', 'Februari': 'February', 'Maret': 'March', 'April': 'April',\n",
        "        'Mei': 'May', 'Juni': 'June', 'Juli': 'July', 'Agustus': 'August',\n",
        "        'September': 'September', 'Oktober': 'October', 'November': 'November', 'Desember': 'December'\n",
        "    }\n",
        "\n",
        "    def convert_date(date_str):\n",
        "        for indo, eng in bulan_dict.items():\n",
        "            if indo in date_str:\n",
        "                return date_str.replace(indo, eng)\n",
        "        return date_str\n",
        "\n",
        "    df_inflasi['Tanggal'] = df_inflasi['Tanggal'].apply(convert_date)\n",
        "    df_inflasi['Tanggal'] = pd.to_datetime(df_inflasi['Tanggal'], format='%B %Y')\n",
        "    df_inflasi['Data Inflasi'] = df_inflasi['Data Inflasi'].str.rstrip('%').astype('float') / 100.0\n",
        "    df_inflasi = df_inflasi.sort_values('Tanggal')\n",
        "    df_inflasi.set_index('Tanggal', inplace=True)\n",
        "\n",
        "    df_trends.index = pd.to_datetime(df_trends.index)\n",
        "    df_trend_monthly = df_trends.resample('M').mean()\n",
        "    df_trend_monthly.index = df_trend_monthly.index - pd.offsets.MonthBegin(1)\n",
        "\n",
        "    df_combined = df_inflasi.join(df_trend_monthly)\n",
        "    df_combined = df_combined.ffill().dropna()\n",
        "    df_combined.reset_index(inplace=True)\n",
        "\n",
        "    # Check for stationarity\n",
        "    def check_stationarity(timeseries):\n",
        "        result = adfuller(timeseries, autolag='AIC')\n",
        "        return result[1] <= 0.05  # p-value <= 0.05 indicates stationarity\n",
        "\n",
        "    # Make series stationary if needed\n",
        "    for col in df_combined.columns:\n",
        "        if col != 'Tanggal' and not check_stationarity(df_combined[col]):\n",
        "            df_combined[f'{col}_diff'] = df_combined[col].diff()\n",
        "\n",
        "    # Feature engineering\n",
        "    for keyword in keywords:\n",
        "        df_combined[f'{keyword}_MA3'] = df_combined[keyword].rolling(window=3).mean()\n",
        "        df_combined[f'{keyword}_MA6'] = df_combined[keyword].rolling(window=6).mean()\n",
        "\n",
        "    # Add time-based features\n",
        "    df_combined['month'] = df_combined['Tanggal'].dt.month\n",
        "    df_combined['quarter'] = df_combined['Tanggal'].dt.quarter\n",
        "\n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    feature_columns = [col for col in df_combined.columns if col != 'Tanggal' and col != 'Data Inflasi']\n",
        "    df_combined[feature_columns] = scaler.fit_transform(df_combined[feature_columns])\n",
        "\n",
        "    # Drop rows with NaN values after feature engineering\n",
        "    df_combined = df_combined.dropna()\n",
        "\n",
        "    return df_combined\n",
        "\n",
        "# 3. Modeling\n",
        "\n",
        "def train_models(X, y, n_splits=3):\n",
        "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "    models = {\n",
        "        'Linear Regression': LinearRegression(),\n",
        "        'Ridge Regression': Ridge(alpha=1.0),\n",
        "        'Lasso Regression': Lasso(alpha=1.0),\n",
        "        'ElasticNet': ElasticNet(alpha=1.0, l1_ratio=0.5),\n",
        "        'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42),\n",
        "        'Support Vector Regression': SVR(kernel='rbf')\n",
        "    }\n",
        "\n",
        "    results = {name: {'RMSE': [], 'R2': [], 'MAPE': []} for name in models}\n",
        "\n",
        "    for train_index, test_index in tscv.split(X):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        for name, model in models.items():\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "\n",
        "            rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "            r2 = r2_score(y_test, y_pred)\n",
        "            mape = mean_absolute_percentage_error(y_test, y_pred)\n",
        "\n",
        "            results[name]['RMSE'].append(rmse)\n",
        "            results[name]['R2'].append(r2)\n",
        "            results[name]['MAPE'].append(mape)\n",
        "\n",
        "    # Calculate average metrics across all folds\n",
        "    for name in models:\n",
        "        results[name]['avg_RMSE'] = np.mean(results[name]['RMSE'])\n",
        "        results[name]['avg_R2'] = np.mean(results[name]['R2'])\n",
        "        results[name]['avg_MAPE'] = np.mean(results[name]['MAPE'])\n",
        "        results[name]['model'] = models[name]\n",
        "\n",
        "    return results\n",
        "\n",
        "# 4. Evaluation\n",
        "\n",
        "def print_evaluation_results(results):\n",
        "    for model_name, metrics in results.items():\n",
        "        print(f\"\\n{model_name}:\")\n",
        "        print(f\"  Average RMSE: {metrics['avg_RMSE']:.4f}\")\n",
        "        print(f\"  Average R2: {metrics['avg_R2']:.4f}\")\n",
        "        print(f\"  Average MAPE: {metrics['avg_MAPE']:.4f}\")\n",
        "        print(f\"  RMSE per fold: {', '.join([f'{rmse:.4f}' for rmse in metrics['RMSE']])}\")\n",
        "        print(f\"  R2 per fold: {', '.join([f'{r2:.4f}' for r2 in metrics['R2']])}\")\n",
        "        print(f\"  MAPE per fold: {', '.join([f'{mape:.4f}' for mape in metrics['MAPE']])}\")\n",
        "\n",
        "# 5. Prediction\n",
        "\n",
        "def predict_inflation(best_model, X_nowcast):\n",
        "    predicted_inflation = best_model.predict(X_nowcast)\n",
        "    return predicted_inflation[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Main execution\n",
        "\n",
        "# Define keywords\n",
        "keywords = ['inflasi', 'harga naik', 'kenaikan harga', 'ekonomi', 'krisis', 'minyak mahal', 'beras langka', 'hidup susah']\n",
        "\n",
        "# 1. Data Collection\n",
        "df_inflasi = scrape_inflasi()\n",
        "df_trends = fetch_google_trends(keywords)\n",
        "\n",
        "# 2. Data Preprocessing\n",
        "df_combined = improved_preprocess_data(df_inflasi, df_trends, keywords)\n",
        "\n",
        "# Feature selection\n",
        "def select_features(X, y):\n",
        "    f_scores, _ = f_regression(X, y)\n",
        "    return pd.Series(f_scores, index=X.columns).sort_values(ascending=False)\n",
        "\n",
        "feature_columns = [col for col in df_combined.columns if col not in ['Tanggal', 'Data Inflasi']]\n",
        "X = df_combined[feature_columns]\n",
        "y = df_combined['Data Inflasi']\n",
        "\n",
        "feature_importance = select_features(X, y)\n",
        "print(\"\\nFeature Importance:\")\n",
        "print(feature_importance)\n",
        "\n",
        "# Select top 5 features\n",
        "top_features = feature_importance.nlargest(5).index.tolist()\n",
        "X = df_combined[top_features]\n",
        "\n",
        "# 3. Modeling\n",
        "model_results = train_models(X, y)\n",
        "\n",
        "# 4. Evaluation\n",
        "print_evaluation_results(model_results)\n",
        "\n",
        "# 5. Prediction\n",
        "best_model_name = min(model_results, key=lambda x: model_results[x]['avg_RMSE'])\n",
        "best_model = model_results[best_model_name]['model']\n",
        "\n",
        "latest_data = df_combined.iloc[-1][top_features].values.reshape(1, -1)\n",
        "predicted_inflation = predict_inflation(best_model, latest_data)\n",
        "print(f\"\\nPredicted Inflation for next month using {best_model_name}: {predicted_inflation:.4f}\")\n",
        "\n",
        "# Visualize actual vs predicted values\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(df_combined['Tanggal'], df_combined['Data Inflasi'], label='Actual Inflation')\n",
        "plt.plot(df_combined['Tanggal'], best_model.predict(X), label='Predicted Inflation')\n",
        "plt.title('Actual vs Predicted Inflation')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Inflation')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TrBGUOL4EW-3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}